{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"[1] _yL Data Preprocessing.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","metadata":{"id":"UfilmkbRWWqi","executionInfo":{"status":"ok","timestamp":1632904150662,"user_tz":-540,"elapsed":1375,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}}},"source":["import cv2\n","import numpy as np\n","import pandas as pd\n","import os\n","import scipy.stats as sp\n","import glob\n","import time\n","from datetime import datetime"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xid6Fy4nX4s7","executionInfo":{"status":"ok","timestamp":1632904169430,"user_tz":-540,"elapsed":18771,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}},"outputId":"6e9bf830-2dc7-42f7-9634-a93f0955b11b"},"source":["# 구글 드라이브랑 연동시키는 코드\n","# 데이터 불러오기 위해서 필요\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"2AnaNoM5WWql"},"source":["## Change name of folder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iH-461P6WWqm","executionInfo":{"status":"ok","timestamp":1632843816488,"user_tz":-540,"elapsed":241,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}},"outputId":"c83d6df9-d3b5-4e24-df3d-295e79fcfe1f"},"source":["# cycle_start = 1\n","# cycle_end = 4\n","\n","case_list = [2,3,5,6]\n","\n","# start = 1\n","# end = 15\n","\n","# rep = 6\n","# py = \"D:/Monitoring/Main/Image/{0}/pyrometer\".format(c)\n","\n","\n","ccd = \"/content/drive/Shareddrives/S-hero 디독스팀/ccd/\" #이미지 데이터 경로\n","py = \"/content/drive/Shareddrives/S-hero 디독스팀/pyrometer/\" #고온계 데이터 경로\n","\n","fl = os.listdir(ccd)\n","print(fl)\n","# for case in case_list:\n","#     os.rename(ccd+\"{0}\" .format(case), ccd+\"Case{0}\" .format(case)) #이미지 데이터 폴더명 변경(이미 맞게 변경 되어있음)\n","#     os.rename(py+\"{0}.dat\" .format(case), py+\"Case{0}.dat\" .format(case)) #고온계 dat파일명 변경\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['Case2', 'Case3', 'Case5', 'Case6']\n"]}]},{"cell_type":"markdown","metadata":{"id":"jSm_eIhZWWqo"},"source":["## Image data feature extraction"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iL0b98x-WWqp","outputId":"94e8186b-42aa-49cd-9640-a26ea14dd8bf"},"source":["# 1사이클 내 start case부터 end case까지 이미지 처리함\n","# start = 1\n","# end = 15\n","\n","\n","# 이미지 처리할 사이클 범위 지정\n","cycle_start = 36\n","cycle_end = 36\n","\n","case_list = [2,3,5,6]\n","\n","for cycle in range(cycle_start, cycle_end+1):\n","    directory = \"/content/drive/Shareddrives/S-hero 디독스팀/ccd\" #이미지 데이터 경로\n","    save_dir = \"/content/drive/Shareddrives/S-hero 디독스팀/extracted_feature\"  #추출된 특징값 행렬 저장 경로\n","    \n","    if not os.path.isdir(save_dir):\n","        os.mkdir(save_dir)\n","    \n","    for case in case_list:\n","        initial_dir = directory + '/Case{0}/'.format(case)\n","\n","      \n","        #폴더 생성 *******************************************\n","        dir_name = initial_dir + \"/Thresholding\" \n","        if not os.path.isdir(dir_name):\n","            os.mkdir(dir_name)\n","        # ****************************************************\n","\n","\n","    #     파일명 변경 *******************************************\n","        # files = os.listdir(initial_dir)\n","        # files = sorted(files, key=lambda k: (len(k.split('-')[-1].split('.')[0]))) #각 이미지 파일들 하이픈 뒤의 마지막 숫자 오름차순 정렬\n","\n","        # t=0\n","        # for f in files:\n","        #     t+=1\n","        #     if \"jpg\" in f:\n","        #         os.rename(initial_dir+f,initial_dir+\"Case{0} ({1}).jpg\".format(case,t))\n","        #     if t%100 == 0:\n","        #         print(\"{0} - Case {1} : Renaming....{2}/{3}\" .format(cycle, case, t,len(files)))\n","\n","        # print('************** Renaming  End  **************')\n","    #     ******************************************************\n","\n","        fps = 30 # CCD sampling frequency\n","        start_time = time.time() # 코드 시작 시간\n","\n","        #파일경로에 있는 이미지 이름 리스트 생성\n","        path = initial_dir\n","        save_path = dir_name\n","        img_path = path+'/*.jpg'\n","        image_name = glob.glob(img_path)\n","        print(\"Case {0} : num of image: {1}\" .format(case, len(image_name)))\n","\n","        valid_image_number = []\n","\n","        # 번호대로 순서 정렬\n","        image_name = sorted(image_name, key=lambda f: int(f.split(' ')[-1].split('.')[0][1:-1]))\n","        num_image = len(image_name)\n","\n","        # 추출할 특징값 리스트\n","        feature_name = ['Area', 'Aspect ratio', 'Width', 'Height', \"Center_X\", \"Center_Y\"\n","                        , 'E_aspect ratio', 'Ellipse_1', \"Ellipse_2\", 'Angle', 'Mean_val'\n","                        ,'Max_val', 'Intensity', 'Extent', 'Solidity']\n","        \n","        # 특징값 저장될 배열 생성\n","        feature = np.zeros([num_image,len(feature_name)])\n","\n","        i=0\n","        for fname in image_name:\n","            i+=1\n","\n","            if i%100 == 0:\n","                print(\"{0} - Case {1} : Mask Making....{2}/{3}\" .format(cycle, case, i,len(image_name)))\n","\n","            if i == len(image_name):\n","                print('**************  End  **************n')\n","\n","            img = cv2.imread(fname)\n","\n","            # 이미지 반시계방향 90도 회전\n","            h,w,_ = img.shape\n","            matrix = cv2.getRotationMatrix2D((w/2, h/2), 90, 1)\n","            img = cv2.warpAffine(img, matrix, (w, h))\n","\n","            img_g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Gray 이미지\n","            ret, img_t = cv2.threshold(img_g, 120, 255, cv2.THRESH_BINARY) # Thresholding\n","            img_c = cv2.cvtColor(img_g, cv2.COLOR_GRAY2RGB) # RGB 이미지    \n","            img_mask = cv2.bitwise_and(img_g, img_g, mask=img_t) # 마스크 이미지\n","\n","            contours, hierarchy = cv2.findContours(img_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","\n","            # 이미지 내 컨투어가 하나 뿐일 때\n","            if len(contours) != 1:\n","                contours = np.array(contours)\n","            cnt = np.zeros_like(contours)\n","            area = np.zeros_like(contours)\n","\n","            # 이미지 내 컨투어가 다수 존재할 때 \n","            for j in range(len(contours)):\n","                cnt[j] = len(contours[j])\n","                area[j] = cv2.contourArea(contours[j])\n","\n","            #컨투어가 있을 경우, 가장 큰 컨투어 찾기\n","            try: \n","                if len(contours) == 1:\n","                    contour = contours\n","                else:\n","                    max_area = max(area) #가장 큰 면적의 컨투어\n","                    ind = np.where(area == max_area)\n","                    contour = contours[ind]  # 이미지의 컨투어\n","\n","                # 마스크 통해 ROI 생성\n","                zero = np.zeros_like(img_g)\n","                cv2.drawContours(zero, contour, 0, (255), -1)\n","                roi = cv2.bitwise_and(img_g, img_g, mask=zero)\n","\n","                #특징값 추출\n","                area = cv2.contourArea(contour[0]) # Area : 용융풀 면적(픽셀 개수)\n","                x,y,width,height = cv2.boundingRect(contour[0]) # Width / Height : 용융풀 너비, 높이\n","                aspect_ratio = float(width)/height # Aspect ratio : 용융풀 종횡비\n","                moment = cv2.moments(contour[0])\n","                center_x = int(moment['m10']/moment['m00']) # Center X : 용융풀 X좌표\n","                center_y = img.shape[0] - int(moment['m01']/moment['m00']) # Center Y : 용융풀 Y좌표\n","                \n","                # 용융풀 ROI를 타원에 매핑 --> Ellipse_1(장축), Ellipse_2(단축), Angle(타원 장축-단축 각도)\n","                (x,y),(ellipse_1,ellipse_2),angle = cv2.fitEllipse(contour[0])\n","                e_aspect_ratio = float(ellipse_2)/ellipse_1 # E_aspect ratio : 용융풀 ROI 타원 종횡비\n","                mean_val = cv2.mean(img_g, mask=zero)[0] # Mean_val : 용융풀의 grayscale 평균\n","                max_val = np.max(img_g) # Max_val : 용융풀 grayscale의 최대값\n","                intensity = mean_val * area # Intensity : 용융풀 총 grayscale (mean_val * area)\n","                extent = area/(width*height) # Extent : 용융풀 bounding rect에 대한 용융풀 면적의 비\n","\n","                hull = cv2.convexHull(contour[0]) \n","                solidity = area/cv2.contourArea(hull) # Solidity : 용융풀 Convexhull에 대한 용융풀 면적 비\n","\n","                #특징값 저장\n","                feature[i-1,:] = [area, aspect_ratio, width, height, center_x, center_y\n","                                  , e_aspect_ratio, ellipse_1, ellipse_2, angle, mean_val\n","                                  , max_val, intensity, extent, solidity]\n","\n","            # ROI 이미지 저장\n","                save_name = save_path+'/ROI ({0}).jpg' .format(i)\n","                cv2.imwrite(save_name, roi)\n","\n","            except:  #컨투어가 없을 경우 특징값 0으로 저장\n","                feature[i-1,:] = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","\n","                save_name = save_path+'/ROI ({0}).jpg' .format(i)\n","                cv2.imwrite(save_name, img)\n","\n","        print(\"time : \", time.time()-start_time, '(s)\\n')\n","\n","        # 특징값 csv파일로 저장\n","        result_name = save_dir + '/{0}-Case{1}.csv'.format(cycle, case)\n","        result = pd.DataFrame(feature, index=np.arange(0, feature.shape[0])/fps,columns=feature_name)\n","        result.to_csv(result_name, header=feature_name)\n","\n","        \n","now = datetime.now()\n","print('\\n\\n>>>> {0}' .format(now.isoformat().split('T')[0]))\n","print('>>>> {0}' .format(now.isoformat().split('T')[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Case 2 : num of image: 1017\n"]}]},{"cell_type":"markdown","metadata":{"id":"rAVHq021WWqv"},"source":["## Pyrometer data feature extraction"]},{"cell_type":"code","metadata":{"id":"doQ-41KqWWqy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632839385641,"user_tz":-540,"elapsed":4876,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}},"outputId":"9fec48c0-8957-47dc-d699-a7607b8c0df0"},"source":["# c = 15\n","# start=1\n","# end=15\n","\n","case_list = [2,3,5,6]\n","\n","cycle_start = 36\n","cycle_end = 36\n","\n","# 데이터 이름 정의\n","for cycle in np.arange(cycle_start, cycle_end+1):\n","    data_directory_py = \"/content/drive/Shareddrives/S-hero 디독스팀/pyrometer/\"  #dat 저장된 경로\n","    csv_save_directory = \"/content/drive/Shareddrives/S-hero 디독스팀/pyrometer/processed/\" #csv 저장할 경로\n","    save_directory = '/content/drive/Shareddrives/S-hero 디독스팀/extracted_feature/pyrometer/' #처리된 데이터 저장할 경로\n","    \n","#     processed_dir_py = save_directory + '/processed'\n","\n","    # 폴더가 없으면 폴더 생성\n","    if not os.path.isdir(csv_save_directory):\n","        os.mkdir(csv_save_directory)\n","    if not os.path.isdir(save_directory):\n","        os.mkdir(save_directory)\n","\n","    for case in case_list:\n","        print(\"{0}-Case{1} : Processing...\" .format(cycle,case))    \n","        f_name_py = data_directory_py + \"Case{0}.dat\" .format(case)\n","#         f_name_py = data_directory_py + \"case{0}.dat\" .format(case)\n","\n","        #데이터 불러오기\n","        f_py = open(f_name_py, 'r',encoding = 'unicode_escape')\n","\n","        # 앞 뒤 열 제거 (이상한 정보 빼기)\n","        f_py = pd.DataFrame(f_py)[9:-2][0]\n","\n","        # 데이터 나누기 \n","        f_split = pd.DataFrame(f_py.str.split('\\t').tolist())\n","\n","        # 시간, 온도 데이터만 select\n","        data_py = pd.DataFrame({'Time' : f_split[0], 'Temp' : f_split[1]})\n","\n","        # csv파일로 저장\n","        data_py.to_csv(csv_save_directory+'Case{0}.csv'.format(case))\n","\n","        # 레이저 꺼진 데이터 빼기\n","        beg_py = 0\n","        end_py = 0\n","        row_num_py = data_py.shape[0] #데이터 개수\n","        layers_py = [] # track별 데이터\n","        num_py = [] # #track별 데이터 개수\n","        thres_py = 490\n","\n","#         successive_data_py = np.zeros((1,5))\n","        \n","        #레이저 꺼진 데이터 빼기\n","        for i in np.arange(row_num_py-1):\n","#             successive_data_py[:] = data_py.iloc[i:i+, 1].values.reshape(1,5)\n","#             if np.float(data_py.iloc[i,1])<=800 and np.float(data_py.iloc[i+1,1])<=800: #연속된 두 데이터가 threshold보다 작을 때\n","            if np.float(data_py.iloc[i,1])==thres_py and np.float(data_py.iloc[i+1,1])==thres_py:\n","#             if np.all(successive_data_py == thres_py):\n","                beg_py = i+1\n","\n","#             if np.float(data_py.iloc[i,1])>800 and np.float(data_py.iloc[i+1,1])<=800:\n","            if np.float(data_py.iloc[i,1])!=thres_py and np.float(data_py.iloc[i+1,1])==thres_py:\n","#             if successive_data_py[0][0] != thres_py and np.all(successive_data_py[0][1:] == thres_py):\n","                end_py = i\n","                layers_py.append((beg_py+4, end_py-4))\n","                num_py.append(end_py-4-beg_py-4)\n","\n","        layers_py = layers_py[3:-2]\n","        num_py = num_py[3:-2]\n","        processed_path_py = save_directory + '/{0}-Case{1}.csv'.format(cycle,case)\n","        sampling_f = 10\n","\n","        new_data_py = np.zeros((0,1))\n","\n","\n","        for layer in layers_py:\n","            layer_data = data_py.iloc[layer[0]:layer[1], 1].values.reshape(-1,1)\n","            new_data_py = np.concatenate((new_data_py, layer_data), axis=0)\n","\n","\n","#         try:\n","        new_data_py = pd.DataFrame(new_data_py, index=np.arange(0, new_data_py.shape[0])/sampling_f, columns=data_py.columns[1:] )\n","        new_data_py.to_csv(processed_path_py)\n","\n","#         except:\n","#             new_data_py = pd.DataFrame(new_data_py, index=np.arange(0, new_data_py.shape[0]/sampling_f-0.5/sampling_f, 1/sampling_f), columns=data_py.columns[1:] )\n","#             new_data_py.to_csv(processed_path_py)\n","\n","now = datetime.now()\n","print('\\n\\n>>>> {0}' .format(now.isoformat().split('T')[0]))\n","print('>>>> {0}' .format(now.isoformat().split('T')[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["36-Case2 : Processing...\n","36-Case3 : Processing...\n","36-Case5 : Processing...\n","36-Case6 : Processing...\n","\n","\n",">>>> 2021-09-28\n",">>>> 14:29:45.524265\n"]}]},{"cell_type":"markdown","metadata":{"id":"Sh2AlocyWWq0"},"source":["## Data preprocessing _ 수정필요"]},{"cell_type":"code","metadata":{"id":"NqUTLzoVWWq1","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"error","timestamp":1632904171386,"user_tz":-540,"elapsed":1007,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}},"outputId":"5a33ec1c-e045-4df1-dd5f-322a1bb117a4"},"source":["cycle_start = 36\n","cycle_end = 36\n","start = 1\n","end = 15\n","\n","case_list = [2,3,5,6]\n","\n","for cycle in np.arange(cycle_start, cycle_end+1):\n","    directory = '/content/drive/Shareddrives/S-hero 디독스팀/extracted_feature/' ############### 저장된 피쳐 경로\n","    \n","    num_of_layers = [] # 공정변수별 트랙 개수 저장할 배열\n","\n","    processed_dir = directory + '/processed' # 전처리 데이터 저장할 폴더 경로\n","\n","    if not os.path.isdir(processed_dir):\n","        os.mkdir(processed_dir)\n","\n","    for case in case_list:\n","        print(\"{0}-Case{1} : Processing...\" .format(cycle,case))\n","\n","        path = directory + '/{0}-Case{1}.csv'.format(cycle,case)\n","\n","        data = pd.read_csv(path) # 특징값 데이터 불러오기\n","\n","        row_num = data.shape[0] \n","        col_num = data.shape[1]\n","\n","\n","        track_beg = 0\n","        track_end = 0\n","        layers = [(0,0)]\n","        num = []\n","\n","        successive_data = np.zeros((1,5))\n","        \n","        ## 레이저 꺼진 데이터 빼기\n","        for i in np.arange(row_num-4):\n","            successive_data[:] = data.iloc[i:i+5]['Area'].values.reshape(1,5)\n","            if np.all(successive_data == 0): #아직 안생김, track_beg을 5칸 뒤로 이동 =>시작점 찾기\n","                track_beg = i+5\n","\n","            if successive_data[0][0] != 0 and np.all(successive_data[0][1:] == 0): #첫번째 넓이 0이 아닌데 그 뒤의 나머지는 0 => 맨 끝 도달\n","                track_end = i\n","                \n","                \n","                if track_end!=track_beg and track_beg!=(layers[-1][0]-13): #1 개만 스파크튀어서 값이 떳을때 제외\n","                    layers.append((track_beg+13, track_end-11)) # 가감속 구간 영향 제외하려고 앞 뒤로 데이터 지우기\n","                    num.append(track_end - 13 - track_beg - 11) # layer당 데이터 갯수 count\n","        \n","        # 앞에 3개의 데이터 버리기(첫번째 데이터는 레이저 안정화 트랙, 두세번째 데이터는 에열되는 트랙의 데이터)\n","        # 뒤에 2개의 데이터 버리기(애칭된 절단면 노이즈 때문)\n","        # 데이터의 시작과 끝의 인덱싱을 모아둔 리스트\n","        laser_start_index = layers[1][0] #레이저가 제일 처음나올때 데이터 인덱스\n","        ref_Center_Y = data.iloc[laser_start_index, 6]\n","\n","        layers = layers[4:-2] #제일 처음 (0,0) 추가해서 한 개 더빼기\n","        num = num[3:-2]\n","        num_of_layers.append(len(num))\n","\n","        processed_path = processed_dir + '/{0}-processed_case{1}.csv'.format(cycle,case)\n","\n","        fps = 30\n","\n","        # Center_Y 상대값\n","        data.iloc[:,6] = data.iloc[:,6] - ref_Center_Y\n","        \n","        new_data = np.zeros((0,col_num-1))\n","\n","        for layer in layers:\n","            new_data = np.concatenate((new_data, data.iloc[layer[0]:layer[1], 1:]), axis=0)\n","\n","\n","        new_data = pd.DataFrame(new_data, index=np.arange(0, new_data.shape[0])/fps, columns=data.columns[1:] )\n","        new_data.to_csv(processed_path)\n","\n","    num_of_layers = pd.DataFrame(num_of_layers)\n","    print(\"Num of layers: \",num_of_layers)\n","    num_of_layers.to_csv(processed_dir+\"/num_of_layers.csv\")\n","    \n","now = datetime.now()\n","print('\\n\\n>>>> {0}' .format(now.isoformat().split('T')[0]))\n","print('>>>> {0}' .format(now.isoformat().split('T')[1]))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["36-Case2 : Processing...\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-bcc2212dcdb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# 뒤에 2개의 데이터 버리기(애칭된 절단면 노이즈 때문)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 데이터의 시작과 끝의 인덱싱을 모아둔 리스트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mlaser_start_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#레이저가 제일 처음나올때 데이터 인덱스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mref_Center_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlaser_start_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"YZKesQhnAGA_","executionInfo":{"status":"error","timestamp":1632844604398,"user_tz":-540,"elapsed":1058,"user":{"displayName":"성균관대학교이예림","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14408371109942913071"}},"outputId":"f494133a-939d-41ba-f614-3e768a1c25b0"},"source":["# cycle_start = 36\n","# cycle_end = 36\n","# start = 1\n","# end = 15\n","\n","# case_list = [2,3,5,6]\n","\n","# for cycle in np.arange(cycle_start, cycle_end+1):\n","#     directory = '/content/drive/Shareddrives/S-hero 디독스팀/extracted_feature/' ############### 저장된 피쳐 경로\n","    \n","#     num_of_layers = [] # 공정변수별 트랙 개수 저장할 배열\n","\n","#     processed_dir = directory + '/processed' # 전처리 데이터 저장할 폴더 경로\n","\n","#     for case in case_list:\n","#         print(\"{0}-Case{1} : Processing...\" .format(cycle,case))\n","\n","#         path = directory + '/{0}-Case{1}.csv'.format(cycle,case)\n","\n","#         data = pd.read_csv(path) # 특징값 데이터 불러오기\n","\n","#         row_num = data.shape[0] \n","#         col_num = data.shape[1]\n","#         print(\"case{} shape:\".format(case),data.shape)\n","\n","\n","#         track_beg = 0\n","#         track_end = 0\n","#         layers = [(0,0)]\n","#         num = []\n","\n","#         successive_data = np.zeros((1,5))\n","        \n","#         ## 레이저 꺼진 데이터 빼기\n","#         for i in np.arange(row_num-4):\n","#             successive_data[:] = data.iloc[i:i+5]['Area'].values.reshape(1,5)\n","#             if np.all(successive_data == 0):\n","#                 track_beg = i+5\n","\n","#             if successive_data[0][0] != 0 and np.all(successive_data[0][1:] == 0):\n","#                 track_end = i\n","                \n","                \n","#                 if track_end!=track_beg and track_beg!=(layers[-1][0]-13): #1 개만 스파크튀어서 값이 떳을때 제외\n","#                     layers.append((track_beg+13, track_end-11)) # 가감속 구간 영향 제외하려고 앞 뒤로 데이터 지우기\n","#                     num.append(track_end - 13 - track_beg - 11) # layer당 데이터 갯수 count\n","        \n","#         # 앞에 3개의 데이터 버리기(첫번째 데이터는 레이저 안정화 트랙, 두세번째 데이터는 에열되는 트랙의 데이터)\n","#         # 뒤에 2개의 데이터 버리기(애칭된 절단면 노이즈 때문)\n","#         # 데이터의 시작과 끝의 인덱싱을 모아둔 리스트\n","#         laser_start_index = layers[1][0] #레이저가 제일 처음나올때 데이터 인덱스\n","#         ref_Center_Y = data.iloc[laser_start_index, 6]\n","\n","#         layers = layers[4:-2] #제일 처음 (0,0) 추가해서 한 개 더빼기\n","#         num = num[3:-2]\n","#         num_of_layers.append(len(num))\n","\n","#         processed_path = processed_dir + '/{0}-processed_case{1}.csv'.format(cycle,case)\n","\n","#         fps = 30\n","\n","#         # Center_Y 상대값\n","#         data.iloc[:,6] = data.iloc[:,6] - ref_Center_Y\n","        \n","#         new_data = np.zeros((0,col_num-1))\n","\n","#         for layer in layers:\n","#             new_data = np.concatenate((new_data, data.iloc[layer[0]:layer[1], 1:]), axis=0)\n","\n","\n","#         new_data = pd.DataFrame(new_data, index=np.arange(0, new_data.shape[0])/fps, columns=data.columns[1:] )\n","#         new_data.to_csv(processed_path)\n","\n","#     num_of_layers = pd.DataFrame(num_of_layers)\n","#     print(\"Num of layers: \",num_of_layers)\n","#     num_of_layers.to_csv(processed_dir+\"/num_of_layers.csv\")\n","    \n","# now = datetime.now()\n","# print('\\n\\n>>>> {0}' .format(now.isoformat().split('T')[0]))\n","# print('>>>> {0}' .format(now.isoformat().split('T')[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["36-Case2 : Processing...\n","case2 shape:  (4249, 3)\n","36-Case3 : Processing...\n","case3 shape:  (3150, 3)\n","36-Case5 : Processing...\n","case5 shape:  (2240, 3)\n","36-Case6 : Processing...\n","case6 shape:  (1724, 3)\n","Num of layers:  Empty DataFrame\n","Columns: []\n","Index: []\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-67bd443238ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mnum_of_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Num of layers: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_of_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mnum_of_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/num_of_layers.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/Shareddrives/S-hero 디독스팀/extracted_feature/pyrometer/processed/processed/num_of_layers.csv'"]}]},{"cell_type":"code","metadata":{"id":"EPrRcwyVWWq1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbrWsEv9WWq2"},"source":[""],"execution_count":null,"outputs":[]}]}